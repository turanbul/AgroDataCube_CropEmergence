{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## my token and baseUrl\n",
    "token = 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3N1ZWR0byI6InR1cmFuLmJ1bG11c0BzYXMuY29tIiwicmVzb3VyY2UiOlsiKiJdLCJyZXF1ZXN0X2xpbWl0IjoyNTAwMCwiYXJlYV9saW1pdCI6MS4wRTgsImV4cCI6MTU0ODg4OTIwMCwiaWF0IjoxNTM4OTkyNTQ4LCJpc3N1ZWRkYXRlIjoxNTM4OTkyNTQ4fQ.zLRBZhI2u7SWm6Z0HuSuWPpu0nAUcESySY1FMIv2J-o'\n",
    "base_Url = \"https://agrodatacube.wur.nl/api/v1/rest\"\n",
    "base_params = {\"page_size\":\"1000\",\"page_offset\":\"0\"}\n",
    "base_headers = {'Accept': \"application/json\", 'token': token}\n",
    "\n",
    "import requests\n",
    "import urllib3\n",
    "import pandas as pd\n",
    "import os\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Function to extract tables from AgroDataCube\n",
    "def get_table(add_url, tab_specific_params):\n",
    "    \"\"\" Returns the normalized json table from the API call.\n",
    "    Parameters\n",
    "    ----------\n",
    "    add_url: The add on to the base url to extract the information from the relevant table\n",
    "    headers: Headers needed for the API request (dictionary)\n",
    "    params: parameters required for the API request (dictionary)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Normalized pandas dataFrame\n",
    "    \"\"\" \n",
    "    #Get the request\n",
    "    base_params.update(tab_specific_params)\n",
    "    req = requests.request(\"GET\", base_Url + add_url, headers=base_headers, params=base_params, verify = False)\n",
    "    \"\"\" Note here: The request requires significant amount of time if the request returns empty results\n",
    "    \"\"\"\n",
    "    #Read the text into pandas data frame\n",
    "    try:\n",
    "        table = pd.read_json(req.text)\n",
    "        return pd.io.json.json_normalize(table.features) #return normalized data frame\n",
    "    except ValueError:\n",
    "        if add_url != \"/ahn\":\n",
    "            print(\"The parameters return empty results: \", tab_specific_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Function that converts the geometry coordinates to strings used for the API request\n",
    "def query_string_maker(geometry_coordinates):\n",
    "    \"\"\" Return the string required for the AHN query given the geometry of the field\n",
    "    Parameters\n",
    "    ----------\n",
    "    geometry_coordinates: The geometry.coordinates column value\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    String that can be used for the API call for AHN table\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    fields.loc[0,'geometry.coordinates']:\n",
    "    '[[[[6.6332234, 52.7820422], [6.6353762, 52.7812052], [6.636732, 52.7806833], [6.636004, 52.7800477], [6.6348456, 52.779029], [6.6339393, 52.7782573], [6.6335653, 52.7779318], [6.6333983, 52.7779871], [6.6321727, 52.778466], [6.630755, 52.7790159], [6.6290151, 52.7796832], [6.6273763, 52.7803245], [6.6279933, 52.7809444], [6.6268363, 52.7813831], [6.625738, 52.7818135], [6.626264, 52.7823157], [6.6266558, 52.7821654], [6.628324, 52.7815214], [6.6303975, 52.7807198], [6.6306689, 52.7806124], [6.6306697, 52.7806385], [6.6289106, 52.7813239], [6.6270292, 52.7820557], [6.6262863, 52.7823416], [6.6269024, 52.7829095], [6.627493, 52.7834753], [6.6280795999999995, 52.7840363], [6.6294839, 52.7834914], [6.631288, 52.782802], [6.6332234, 52.7820422]]]]'\n",
    "    \n",
    "    query_string_maker(fields.loc[0,'geometry.coordinates']):\n",
    "        '6.6332234  52.7820422, 6.6353762  52.7812052, 6.636732  52.7806833, 6.636004  52.7800477, 6.6348456  52.779029, 6.6339393  52.7782573, 6.6335653  52.7779318, 6.6333983  52.7779871, 6.6321727  52.778466, 6.630755  52.7790159, 6.6290151  52.7796832, 6.6273763  52.7803245, 6.6279933  52.7809444, 6.6268363  52.7813831, 6.625738  52.7818135, 6.626264  52.7823157, 6.6266558  52.7821654, 6.628324  52.7815214, 6.6303975  52.7807198, 6.6306689  52.7806124, 6.6306697  52.7806385, 6.6289106  52.7813239, 6.6270292  52.7820557, 6.6262863  52.7823416, 6.6269024  52.7829095, 6.627493  52.7834753, 6.6280795999999995  52.7840363, 6.6294839  52.7834914, 6.631288  52.782802, 6.6332234  52.7820422'\n",
    "    \"\"\"\n",
    "    #Remove the square brackets and split each coordinate with a comma\n",
    "    l = str(geometry_coordinates).replace(\"[\",\"\").replace(\"]\", \"\").split(\",\")\n",
    "    #Add comma after every two number\n",
    "    return \",\".join([\" \".join([l[i], l[i+1]]) for i in range(0, len(l), 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Function that checks if the initial coordinates are the same as the last coordinate verifying if the polygon is correct\n",
    "def check_coordinates(coordinate_string):\n",
    "    \"\"\" Checks if the first coordinate in the polygon is the same as the last one\n",
    "    Parameters\n",
    "    ----------\n",
    "    coordinate_string: The new coordinates string derived from query_string_maker function\n",
    "    Returns\n",
    "    -------\n",
    "    True if the polygon has the same end point as the starting point\n",
    "    \"\"\"\n",
    "    return coordinate_string[:coordinate_string.find(\",\")] == coordinate_string[coordinate_string.rfind(\",\")+2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 1) Extract Crop Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>properties.cropcode</th>\n",
       "      <th>properties.cropid</th>\n",
       "      <th>properties.cropname</th>\n",
       "      <th>properties.grondgebruik</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2645</td>\n",
       "      <td>2</td>\n",
       "      <td>Notenbomen</td>\n",
       "      <td>Bouwland</td>\n",
       "      <td>Feature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1908</td>\n",
       "      <td>3</td>\n",
       "      <td>Braak, zwarte- met ontheffing</td>\n",
       "      <td>Braakland</td>\n",
       "      <td>Feature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3718</td>\n",
       "      <td>4</td>\n",
       "      <td>Grasland, natuurlijk</td>\n",
       "      <td>Grasland</td>\n",
       "      <td>Feature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>859</td>\n",
       "      <td>5</td>\n",
       "      <td>Aardappelen, zetmeel geleverd aan buitenland</td>\n",
       "      <td>Bouwland</td>\n",
       "      <td>Feature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3792</td>\n",
       "      <td>6</td>\n",
       "      <td>Aardappelen, consumptie op zand/veengrond</td>\n",
       "      <td>Bouwland</td>\n",
       "      <td>Feature</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  properties.cropcode  properties.cropid  \\\n",
       "0                2645                  2   \n",
       "1                1908                  3   \n",
       "2                3718                  4   \n",
       "3                 859                  5   \n",
       "4                3792                  6   \n",
       "\n",
       "                            properties.cropname properties.grondgebruik  \\\n",
       "0                                    Notenbomen                Bouwland   \n",
       "1                 Braak, zwarte- met ontheffing               Braakland   \n",
       "2                          Grasland, natuurlijk                Grasland   \n",
       "3  Aardappelen, zetmeel geleverd aan buitenland                Bouwland   \n",
       "4     Aardappelen, consumptie op zand/veengrond                Bouwland   \n",
       "\n",
       "      type  \n",
       "0  Feature  \n",
       "1  Feature  \n",
       "2  Feature  \n",
       "3  Feature  \n",
       "4  Feature  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract crop codes\n",
    "add_url = \"/codes/cropcodes\"\n",
    "\n",
    "crop_codes_table = get_table(add_url, tab_specific_params={})\n",
    "crop_codes_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Filter only the relevant crops and also remove voderbits\n",
    "filtered_crops = crop_codes_table[crop_codes_table[\"properties.cropname\"].str.contains(\"Aardappelen|Biet|Ui\")\\\n",
    "                                     & ~crop_codes_table['properties.cropname'].str.contains(\"voeder\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2) Extract Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "add_url = \"/fields\"\n",
    "fields_col_names = ['features','geometry.coordinates', 'geometry.type', 'properties.area',\n",
    "       'properties.crop_code', 'properties.crop_name', 'properties.fieldid',\n",
    "       'properties.perimeter', 'properties.year', 'type']\n",
    "#Empty data frame for the fields\n",
    "fields_data = pd.DataFrame(columns=fields_col_names)\n",
    "#Loop query over the selected crops above\n",
    "for values in filtered_crops['properties.cropcode']:\n",
    "    for years in range(2012, 2019):\n",
    "        querystring = {\"output_epsg\":\"4326\", \"year\":str(years), \"cropcode\": values}\n",
    "        headers = {'Accept': 'application/json;charset=utf-8', 'token': token}\n",
    "        \n",
    "        #Get the query\n",
    "        fields = get_table(add_url, tab_specific_params=querystring)\n",
    "        #Append it to the main data frame\n",
    "        fields_data = fields_data.append(fields, sort=True, ignore_index=True)\n",
    "\n",
    "#Remove irrelevant columns\n",
    "fields = fields_data.drop([\"features\", \"type\"], axis=1)  \n",
    "\n",
    "#Extract new coordinates from coordinates for sending it to API\n",
    "fields[\"new_coordinates\"] = fields['geometry.coordinates'].apply(query_string_maker)\n",
    "\n",
    "#Column checking if the first coordinates in the polygon is the same as the last one\n",
    "fields[\"coordinate_check\"] = fields.new_coordinates.apply(check_coordinates)\n",
    "\n",
    "#Extract wrong field information\n",
    "fields[~fields.coordinate_check].to_csv(directory + \"\\\\Data\\\\problematic fields.csv\")\n",
    "\n",
    "#The fields table should have only correct polygons\n",
    "fields = fields[fields.coordinate_check]\n",
    "#Set the fieldid as the index for the table\n",
    "fields = fields.set_index(\"properties.fieldid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fields = fields.set_index(\"properties.fieldid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Write to csv so that I dont have to run the querry again\n",
    "fields.to_csv(directory + \"\\\\Data\\\\fields.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Extract AHN for each field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the fields data\n",
    "fields= pd.read_csv(directory + \"\\\\Data\\\\fields.csv\", index_col=[\"properties.fieldid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Since information about each field can not be extracted in one go; divide fieldids into batches and run them seperately and\n",
    "#combine them after wards\n",
    "add_url = \"/ahn\"\n",
    "ahn_col_names = ['properties.area', 'properties.max', 'properties.mean', 'properties.min']\n",
    "initial_table = pd.DataFrame(columns=ahn_col_names)# index=['properties.fieldid'])\n",
    "run_until = len(fields)\n",
    "\n",
    "def get_ahn_in_batches(fields_table, table_to_append, initial_row_num, end_row_num):\n",
    "    ahn_data = pd.DataFrame(columns=ahn_col_names)# index=['properties.fieldid'])\n",
    "        \n",
    "    for values in range(initial_row_num, end_row_num):\n",
    "        #Extract the coordinates from the fields table\n",
    "        queries = fields_table.new_coordinates.iloc[values]\n",
    "        querystring = {\"geometry\":\"POLYGON((\" + queries + \"))\",\"epsg\":\"4326\"}\n",
    "\n",
    "        #Get the query\n",
    "        ahn = get_table(add_url, querystring)\n",
    "        \n",
    "        if type(ahn) != type(None): #This is for making sure that there is data acquired from the query\n",
    "            #Add the new column to the ahn table so that it can be joined with fields table later\n",
    "            ahn[\"properties.fieldid\"] = pd.Series(fields_table.index.values[values])\n",
    "            ahn = ahn.set_index('properties.fieldid')\n",
    "            \n",
    "        #Append it to the main data frame\n",
    "        ahn_data = ahn_data.append(ahn, sort=True)\n",
    "    \n",
    "    ahn_data = ahn_data.drop(\"type\", axis = 1)\n",
    "    return table_to_append.append(ahn_data, sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1 = get_ahn_in_batches(fields,initial_table,0,5000)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1.to_csv(directory + \"\\\\Data\\\\table1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table2 = get_ahn_in_batches(fields,table1,5000,10000)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table2.to_csv(directory + \"\\\\Data\\\\table2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table3 = get_ahn_in_batches(fields,table2,10000,20000)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table3.to_csv(directory + \"\\\\Data\\\\table3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table4 = get_ahn_in_batches(fields,table3,20000,25000)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table4.to_csv(directory + \"\\\\Data\\\\table4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table5 = get_ahn_in_batches(fields,table4,25000,run_until)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table5.to_csv(directory + \"\\\\Data\\\\ahn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Extract Soil info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
